{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re \n",
    "import spacy\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    return text\n",
    "\n",
    "def extract_name(doc: spacy.tokens.Doc) -> str:\n",
    "    \"\"\"Extract the person's name using NER (Named Entity Recognition).\"\"\"\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return ent.text\n",
    "    # Fallback: assume name is at the top of the resume (first line)\n",
    "    first_line = doc.text.split('\\n')[0].strip()\n",
    "    return first_line if first_line else \"Name not found\"\n",
    "\n",
    "def extract_email(text: str) -> str:\n",
    "    \"\"\"Extract email address using regex.\"\"\"\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "    match = re.search(email_pattern, text)\n",
    "    return match.group(0) if match else \"Email not found\"\n",
    "\n",
    "def extract_phone(text: str) -> str:\n",
    "    \"\"\"Extract phone number using regex.\"\"\"\n",
    "    phone_pattern = r'(\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}'\n",
    "    match = re.search(phone_pattern, text)\n",
    "    return match.group(0) if match else \"Phone not found\"\n",
    "\n",
    "def extract_skills(doc, skills_list):\n",
    "    \"\"\"Extract skills by matching against a predefined list.\"\"\"\n",
    "    found_skills = set()\n",
    "    text = doc.text.lower()\n",
    "    for skill in skills_list:\n",
    "        if skill.lower() in text:\n",
    "            found_skills.add(skill)\n",
    "    return list(found_skills) if found_skills else [\"No skills matched\"]\n",
    "\n",
    "def extract_education(doc):\n",
    "    \"\"\"Extract education details.\"\"\"\n",
    "    education_keywords = {\"university\", \"college\", \"institute\", \"school\", \"bachelor\", \"master\", \"phd\", \"degree\"}\n",
    "    education = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in {\"ORG\", \"DATE\"} and any(keyword in ent.text.lower() for keyword in education_keywords):\n",
    "            education.append(ent.text)\n",
    "    return education if education else [\"Education not found\"]\n",
    "\n",
    "def parse_resume(model, pdf_path, skills_list):\n",
    "    \"\"\"Main function to parse resume and extract information.\"\"\"\n",
    "    # Extract text from PDF\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        return {\"error\": \"No text extracted from resume\"}\n",
    "\n",
    "    # Process text with spaCy\n",
    "    doc = model(text)\n",
    "\n",
    "    # Extract information\n",
    "    resume_data = {\n",
    "        \"name\": extract_name(doc),\n",
    "        \"email\": extract_email(text),\n",
    "        \"phone\": extract_phone(text),\n",
    "        \"skills\": extract_skills(doc, skills_list),\n",
    "        \"education\": extract_education(doc)\n",
    "    }\n",
    "    return resume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harry Nguyen\\nÂ§ hainguyen2903.github.io/gitprofile | (cid:239) linkedin.com/in/nguyenphuchai | # hainguyen29031412@gmail.com\\nEDUCATION\\nUniversity of Technology Sydney (UTS) August 2023 - August 2025\\nMasterâ€™s Degree in Data Science (Postgraduate Excellence International Scholarship)\\nUniversity of Engineering and Technology, Vietnam National University August 2018 - August 2022\\nBachelorâ€™s Degree in Computer Science\\nGPA: 3.51/4.0 Thesis score: 9.1/10\\nSKILLS AND KNOWLEDGE\\nBackground Knowledge Machine Learning, Computer Vision, Natural Language Processing\\nData Analysis Skills Tableau, Seaborn, Matplotlib, AWS\\nProgram Languages Python, SQL\\nData Enigineer Skills Azure, Databrick, Airflow, dbt\\nSoft Skills Teamwork, Self-Studying, Leadership, Problem Solving\\nWORKING EXPERIENCE\\nMachine Learning Engineer (SiliconCube Company) July 2022 - June 2023\\nâ€¢ Smart Parking System - Car Detection and License Plate Recognition\\nAn automatic parking monitoring system, which includes license plate recognition and parking slots monitoring.\\nResponsibility:\\nâ€“ Experimented, error analysed and intergrated multiple models (YOLOv5, WPOD-Net, ...), resulted in more\\nthan 98% in term of accuracy.\\nâ€“ Deployed trained model on NVIDIA Jetson Xavier device. Built server-client protocol to verified system pipeline\\nand dockerized product.\\nâ€¢ Smart Advisor for Online Learning Platform\\nAn AI system for tracking student knowledge level and recommending essential learning materials based on their historical\\nacademic performance.\\nResponsibility:\\nâ€“ Experimented, error analysed and intergrated multiple deep models to achieve high performance.\\nâ€“ Created pipeline for system continuous training and monitoring using Wandb.\\nComputer Vision Research Engineer (AI Lab - UET) April 2020 - August 2022\\nâ€¢ Real Time Multiple Cameras Surveillance System [Link]\\nAreal-timeMultipleTargetsTrackingsystemwith50camerasand12differentobservationareasina5-floorbuilding.\\nResponsibility:\\nâ€“ Researched, developed and ensembled several detection models for comparative analysis (mostly YOLOv5 and\\nCenterNet).\\nâ€“ Research, optimized and benchmarked different tracking models (DeepSORT, FairMOT), resulted in approxi-\\nmately 85% in term of MOTA metric on collected dataset.\\nâ€“ Leaded data team and annotation pipeline, including data collection, extraction, annotation and quality\\nverification.\\nâ€“ Created partial automation pipeline with re-identification models to support annotation process, resulted\\nin x2 annotation speed compared to traditional method.\\nâ€“ Collaborated to generate the largest multiple-camera tracking dataset compared to existing datasets in\\nterms of camera, tracking area, and human ID quantities.\\nâ€“ Collaborated to design new algorithm for tracking across multiple cameras using different techniques, namely\\ncamera calibration, top-view representation, feature matching, etc.DATA SCIENCE PROJECTS\\nâ€¢ Airbnb ad-hoc analyses with Big Data November 2024\\nEnd-to-end ELT pipeline and ad hoc analysis from raw data to key insights for the optimization of Airbnb strategies.\\nResponsibility:\\nâ€“ Deployed a production-ready ELT data pipeline, automating tasks with Apache Airflow and dbt Cloud.\\nâ€“ Organized data using a medallion architecture and enabled ad-hoc analysis with data marts.\\nâ€“ Delivered ad-hoc analyses that provided actionable insights for key business decisions.\\nâ€¢ NSW Traffic Analysis for Road Maintenance Optimization [Link] June 2024\\nA story-telling project with advanced visualizations for NSW Road Maintenance Optimization.\\nResponsibility:\\nâ€“ Performed different data processing and transformation techniques on the the source data set (dedupicating,\\naggregation, joining, etc.).\\nâ€“ LeveragedTableauforcomplexvisualizations,includinggeographicalheatmaps,multi-levelbarcharts,time-series\\ncharts, and combined charts.\\nâ€“ Designed storyline with effective visualizations (i.e., color highlighting, group comparisons, etc.) to deliver valu-\\nable business insights to audience.\\nâ€¢ AWS Elastic Beanstalk PaaS for LAMP stack application June 2024\\nThe project aims to implement a scalable, elastic, highly available, and fault-tolerant PaaS for business needs.\\nResponsibility:\\nâ€“ Implemented a PaaS with different AWS services, including EC2, Load Balancer, Auto Scaling Group, RDS,\\nVPC, etc. that allows businesses to fully customize for their LAMP stack application.\\nâ€¢ Banking Customer Segmentation [Link] June 2024\\nThe project leverages the bankâ€™s extensive transactional data collected over the past three years to develop machine\\nlearning for segmenting customers based on spending behaviors, facilitating personalized marketing.\\nResponsibility:\\nâ€“ Performed comprehensive data exploratory to identify important features for model development.\\nâ€“ Leveragedoriginalfeaturestogenerateamorereliablefeatureset(i.e. RFMvalues)forbettercustomerclustering.\\nâ€“ ExperimentedvariousclusteringmodelswhichincludesDBSCANandKMeans,combiningwithPCAtooptimize\\nmodel weight and performance.\\nâ€¢ Telecom Customer Understanding [Link] August 2023\\nThe project aims to obtain a comprehensive understanding of customer groups from companyâ€™s past marketing cam-\\npaigns to identify new strategies for the upcoming campaign through the development of the EDA and ML model\\ndevelopment.\\nResonsibility:\\nâ€“ Applied various EDA techniques (visualization, univariate and bivariate analysis, etc.) to draw comprehensive\\ninsights of customers and external contexts of the given dataset.\\nâ€“ Leveraged hypothesis testing to verify generated hypothesis of variable relationships.\\nâ€“ Developed various classification models, including XGBoost and TPE hyperparams optimization, to extract\\ninsights from different customer segments.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/hainguyen/Desktop/Harry_Nguyen_Resume.pdf'\n",
    "\n",
    "text = extract_text_from_pdf(path)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Resume Information:\n",
      "Name: Harry Nguyen\n",
      "Â§\n",
      "Email: hainguyen29031412@gmail.com\n",
      "Phone: Phone not found\n",
      "Skills: ['SQL', 'Machine Learning', 'Data Analysis', 'Python', 'AWS']\n",
      "Education: ['University of Technology Sydney', 'University of Engineering and Technology', 'Vietnam National University', 'Bachelorâ€™s Degree']\n"
     ]
    }
   ],
   "source": [
    "model = spacy.load('en_core_web_sm')\n",
    "\n",
    "# processed_text = model(text)\n",
    "# processed_text\n",
    "\n",
    "sample_skills = [\n",
    "        \"Python\", \"Java\", \"Machine Learning\", \"SQL\", \"JavaScript\",\n",
    "        \"Project Management\", \"Data Analysis\", \"C++\", \"React\", \"AWS\"\n",
    "    ]\n",
    "\n",
    "\n",
    "# Parse the resume\n",
    "result = parse_resume(model, path, sample_skills)\n",
    "\n",
    "# Print results\n",
    "print(\"Extracted Resume Information:\")\n",
    "for key, value in result.items():\n",
    "    print(f\"{key.capitalize()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Resume Information:\n",
      "Name: HENRY LE\n",
      "Email: nhathoangle1312@gmail.com\n",
      "Phone: Phone not found\n",
      "Skills: ['SQL', 'Machine Learning', 'Data Analysis', 'Python', 'AWS']\n",
      "Education: ['UNIVERSITY OF TECHNOLOGY SYDNEY', 'KENT INSTITUTE UNIVERSITY', 'Bachelor of Accounting\\nâ€¢ Focus', 'CURTIN UNIVERSITY']\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/hainguyen/Downloads/Henry CV.pdf'\n",
    "\n",
    "result = parse_resume(model, path, sample_skills)\n",
    "\n",
    "# Print results\n",
    "print(\"Extracted Resume Information:\")\n",
    "for key, value in result.items():\n",
    "    print(f\"{key.capitalize()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>pay_period</th>\n",
       "      <th>location</th>\n",
       "      <th>company_id</th>\n",
       "      <th>views</th>\n",
       "      <th>med_salary</th>\n",
       "      <th>...</th>\n",
       "      <th>skills_desc</th>\n",
       "      <th>listed_time</th>\n",
       "      <th>posting_domain</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>work_type</th>\n",
       "      <th>currency</th>\n",
       "      <th>compensation_type</th>\n",
       "      <th>normalized_salary</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Requirements: \\n\\nWe are seeking a College or ...</td>\n",
       "      <td>1.713398e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>38480.0</td>\n",
       "      <td>8540.0</td>\n",
       "      <td>34021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1829192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Fort Collins, CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.712858e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>80521.0</td>\n",
       "      <td>8069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998357</td>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>We are currently accepting resumes for FOH - A...</td>\n",
       "      <td>1.713278e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>45202.0</td>\n",
       "      <td>39061.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     job_id            company_name                              title  \\\n",
       "0    921716   Corcoran Sawyer Smith              Marketing Coordinator   \n",
       "1   1829192                     NaN  Mental Health Therapist/Counselor   \n",
       "2  10998357  The National Exemplar         Assitant Restaurant Manager   \n",
       "\n",
       "                                         description  max_salary pay_period  \\\n",
       "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
       "1  At Aspen Therapy and Wellness , we are committ...        50.0     HOURLY   \n",
       "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
       "\n",
       "           location  company_id  views  med_salary  ...  \\\n",
       "0     Princeton, NJ   2774458.0   20.0         NaN  ...   \n",
       "1  Fort Collins, CO         NaN    1.0         NaN  ...   \n",
       "2    Cincinnati, OH  64896719.0    8.0         NaN  ...   \n",
       "\n",
       "                                         skills_desc   listed_time  \\\n",
       "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
       "1                                                NaN  1.712858e+12   \n",
       "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
       "\n",
       "   posting_domain  sponsored  work_type currency compensation_type  \\\n",
       "0             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "1             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "2             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "\n",
       "  normalized_salary  zip_code     fips  \n",
       "0           38480.0    8540.0  34021.0  \n",
       "1           83200.0   80521.0   8069.0  \n",
       "2           55000.0   45202.0  39061.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/linkedin-jobs-2023-2024/postings.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_id', 'company_name', 'title', 'description', 'max_salary',\n",
       "       'pay_period', 'location', 'company_id', 'views', 'med_salary',\n",
       "       'min_salary', 'formatted_work_type', 'applies', 'original_listed_time',\n",
       "       'remote_allowed', 'job_posting_url', 'application_url',\n",
       "       'application_type', 'expiry', 'closed_time',\n",
       "       'formatted_experience_level', 'skills_desc', 'listed_time',\n",
       "       'posting_domain', 'sponsored', 'work_type', 'currency',\n",
       "       'compensation_type', 'normalized_salary', 'zip_code', 'fips'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116       Request: Data ArchitectLocation: San Francisco...\n",
       "134       This opportunity is joining an innovation driv...\n",
       "165       The Enterprise Data Infrastructure and Analyti...\n",
       "283       Data Engineer with Kafka (W2 Only)ðŸ’¯% Remote\\nM...\n",
       "348       Company DescriptionPB Built is a residential c...\n",
       "                                ...                        \n",
       "123475    About This Featured Opportunity\\n\\nWe are look...\n",
       "123580    Role Title: Data Engineering Lead for a global...\n",
       "123727    Overview\\n\\nThe Credit Risk & Decision Science...\n",
       "123770    Overview\\n\\nManage Navy Federal's BSA/AML and ...\n",
       "123845    About Pinterest:\\n\\nMillions of people across ...\n",
       "Name: description, Length: 2720, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720\n"
     ]
    }
   ],
   "source": [
    "# all_titles = df['title'].unique()\n",
    "\n",
    "# titles = ['Data Analyst', 'Data Scientist', 'Data Engineer', 'ML Engineer', 'Machine Learning Engineer', 'AI Engineer',\n",
    "#           'AI Researcher']\n",
    "# df_filter = df[df.title.isin(titles)]\n",
    "\n",
    "title_keywords = ['Data ', 'AI ', 'ML ', 'Machine Learning ']\n",
    "\n",
    "df = df[df.title.str.contains('|'.join(title_keywords), case=False, na=False)]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('job_descs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re \n",
    "import spacy\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    return text\n",
    "\n",
    "def extract_name(doc: spacy.tokens.Doc) -> str:\n",
    "    \"\"\"Extract the person's name using NER (Named Entity Recognition).\"\"\"\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return ent.text\n",
    "    # Fallback: assume name is at the top of the resume (first line)\n",
    "    first_line = doc.text.split('\\n')[0].strip()\n",
    "    return first_line if first_line else \"Name not found\"\n",
    "\n",
    "def extract_email(text: str) -> str:\n",
    "    \"\"\"Extract email address using regex.\"\"\"\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "    match = re.search(email_pattern, text)\n",
    "    return match.group(0) if match else \"Email not found\"\n",
    "\n",
    "def extract_phone(text: str) -> str:\n",
    "    \"\"\"Extract phone number using regex.\"\"\"\n",
    "    phone_pattern = r'(\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}'\n",
    "    match = re.search(phone_pattern, text)\n",
    "    return match.group(0) if match else \"Phone not found\"\n",
    "\n",
    "def extract_skills(doc, skills_list):\n",
    "    \"\"\"Extract skills by matching against a predefined list.\"\"\"\n",
    "    found_skills = set()\n",
    "    text = doc.text.lower()\n",
    "    for skill in skills_list:\n",
    "        if skill.lower() in text:\n",
    "            found_skills.add(skill)\n",
    "    return list(found_skills) if found_skills else [\"No skills matched\"]\n",
    "\n",
    "def extract_education(doc):\n",
    "    \"\"\"Extract education details.\"\"\"\n",
    "    education_keywords = {\"university\", \"college\", \"institute\", \"school\", \"bachelor\", \"master\", \"phd\", \"degree\"}\n",
    "    education = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in {\"ORG\", \"DATE\"} and any(keyword in ent.text.lower() for keyword in education_keywords):\n",
    "            education.append(ent.text)\n",
    "    return education if education else [\"Education not found\"]\n",
    "\n",
    "def parse_resume(model, pdf_path, skills_list):\n",
    "    \"\"\"Main function to parse resume and extract information.\"\"\"\n",
    "    # Extract text from PDF\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        return {\"error\": \"No text extracted from resume\"}\n",
    "\n",
    "    # Process text with spaCy\n",
    "    doc = model(text)\n",
    "\n",
    "    # Extract information\n",
    "    resume_data = {\n",
    "        \"name\": extract_name(doc),\n",
    "        \"email\": extract_email(text),\n",
    "        \"phone\": extract_phone(text),\n",
    "        \"skills\": extract_skills(doc, skills_list),\n",
    "        \"education\": extract_education(doc)\n",
    "    }\n",
    "    return resume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harry Nguyen\\n§ hainguyen2903.github.io/gitprofile | (cid:239) linkedin.com/in/nguyenphuchai | # hainguyen29031412@gmail.com\\nEDUCATION\\nUniversity of Technology Sydney (UTS) August 2023 - August 2025\\nMaster’s Degree in Data Science (Postgraduate Excellence International Scholarship)\\nUniversity of Engineering and Technology, Vietnam National University August 2018 - August 2022\\nBachelor’s Degree in Computer Science\\nGPA: 3.51/4.0 Thesis score: 9.1/10\\nSKILLS AND KNOWLEDGE\\nBackground Knowledge Machine Learning, Computer Vision, Natural Language Processing\\nData Analysis Skills Tableau, Seaborn, Matplotlib, AWS\\nProgram Languages Python, SQL\\nData Enigineer Skills Azure, Databrick, Airflow, dbt\\nSoft Skills Teamwork, Self-Studying, Leadership, Problem Solving\\nWORKING EXPERIENCE\\nMachine Learning Engineer (SiliconCube Company) July 2022 - June 2023\\n• Smart Parking System - Car Detection and License Plate Recognition\\nAn automatic parking monitoring system, which includes license plate recognition and parking slots monitoring.\\nResponsibility:\\n– Experimented, error analysed and intergrated multiple models (YOLOv5, WPOD-Net, ...), resulted in more\\nthan 98% in term of accuracy.\\n– Deployed trained model on NVIDIA Jetson Xavier device. Built server-client protocol to verified system pipeline\\nand dockerized product.\\n• Smart Advisor for Online Learning Platform\\nAn AI system for tracking student knowledge level and recommending essential learning materials based on their historical\\nacademic performance.\\nResponsibility:\\n– Experimented, error analysed and intergrated multiple deep models to achieve high performance.\\n– Created pipeline for system continuous training and monitoring using Wandb.\\nComputer Vision Research Engineer (AI Lab - UET) April 2020 - August 2022\\n• Real Time Multiple Cameras Surveillance System [Link]\\nAreal-timeMultipleTargetsTrackingsystemwith50camerasand12differentobservationareasina5-floorbuilding.\\nResponsibility:\\n– Researched, developed and ensembled several detection models for comparative analysis (mostly YOLOv5 and\\nCenterNet).\\n– Research, optimized and benchmarked different tracking models (DeepSORT, FairMOT), resulted in approxi-\\nmately 85% in term of MOTA metric on collected dataset.\\n– Leaded data team and annotation pipeline, including data collection, extraction, annotation and quality\\nverification.\\n– Created partial automation pipeline with re-identification models to support annotation process, resulted\\nin x2 annotation speed compared to traditional method.\\n– Collaborated to generate the largest multiple-camera tracking dataset compared to existing datasets in\\nterms of camera, tracking area, and human ID quantities.\\n– Collaborated to design new algorithm for tracking across multiple cameras using different techniques, namely\\ncamera calibration, top-view representation, feature matching, etc.DATA SCIENCE PROJECTS\\n• Airbnb ad-hoc analyses with Big Data November 2024\\nEnd-to-end ELT pipeline and ad hoc analysis from raw data to key insights for the optimization of Airbnb strategies.\\nResponsibility:\\n– Deployed a production-ready ELT data pipeline, automating tasks with Apache Airflow and dbt Cloud.\\n– Organized data using a medallion architecture and enabled ad-hoc analysis with data marts.\\n– Delivered ad-hoc analyses that provided actionable insights for key business decisions.\\n• NSW Traffic Analysis for Road Maintenance Optimization [Link] June 2024\\nA story-telling project with advanced visualizations for NSW Road Maintenance Optimization.\\nResponsibility:\\n– Performed different data processing and transformation techniques on the the source data set (dedupicating,\\naggregation, joining, etc.).\\n– LeveragedTableauforcomplexvisualizations,includinggeographicalheatmaps,multi-levelbarcharts,time-series\\ncharts, and combined charts.\\n– Designed storyline with effective visualizations (i.e., color highlighting, group comparisons, etc.) to deliver valu-\\nable business insights to audience.\\n• AWS Elastic Beanstalk PaaS for LAMP stack application June 2024\\nThe project aims to implement a scalable, elastic, highly available, and fault-tolerant PaaS for business needs.\\nResponsibility:\\n– Implemented a PaaS with different AWS services, including EC2, Load Balancer, Auto Scaling Group, RDS,\\nVPC, etc. that allows businesses to fully customize for their LAMP stack application.\\n• Banking Customer Segmentation [Link] June 2024\\nThe project leverages the bank’s extensive transactional data collected over the past three years to develop machine\\nlearning for segmenting customers based on spending behaviors, facilitating personalized marketing.\\nResponsibility:\\n– Performed comprehensive data exploratory to identify important features for model development.\\n– Leveragedoriginalfeaturestogenerateamorereliablefeatureset(i.e. RFMvalues)forbettercustomerclustering.\\n– ExperimentedvariousclusteringmodelswhichincludesDBSCANandKMeans,combiningwithPCAtooptimize\\nmodel weight and performance.\\n• Telecom Customer Understanding [Link] August 2023\\nThe project aims to obtain a comprehensive understanding of customer groups from company’s past marketing cam-\\npaigns to identify new strategies for the upcoming campaign through the development of the EDA and ML model\\ndevelopment.\\nResonsibility:\\n– Applied various EDA techniques (visualization, univariate and bivariate analysis, etc.) to draw comprehensive\\ninsights of customers and external contexts of the given dataset.\\n– Leveraged hypothesis testing to verify generated hypothesis of variable relationships.\\n– Developed various classification models, including XGBoost and TPE hyperparams optimization, to extract\\ninsights from different customer segments.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/hainguyen/Desktop/Harry_Nguyen_Resume.pdf'\n",
    "\n",
    "text = extract_text_from_pdf(path)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Resume Information:\n",
      "Name: Harry Nguyen\n",
      "§\n",
      "Email: hainguyen29031412@gmail.com\n",
      "Phone: Phone not found\n",
      "Skills: ['SQL', 'Machine Learning', 'Data Analysis', 'Python', 'AWS']\n",
      "Education: ['University of Technology Sydney', 'University of Engineering and Technology', 'Vietnam National University', 'Bachelor’s Degree']\n"
     ]
    }
   ],
   "source": [
    "model = spacy.load('en_core_web_sm')\n",
    "\n",
    "# processed_text = model(text)\n",
    "# processed_text\n",
    "\n",
    "sample_skills = [\n",
    "        \"Python\", \"Java\", \"Machine Learning\", \"SQL\", \"JavaScript\",\n",
    "        \"Project Management\", \"Data Analysis\", \"C++\", \"React\", \"AWS\"\n",
    "    ]\n",
    "\n",
    "\n",
    "# Parse the resume\n",
    "result = parse_resume(model, path, sample_skills)\n",
    "\n",
    "# Print results\n",
    "print(\"Extracted Resume Information:\")\n",
    "for key, value in result.items():\n",
    "    print(f\"{key.capitalize()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Resume Information:\n",
      "Name: HENRY LE\n",
      "Email: nhathoangle1312@gmail.com\n",
      "Phone: Phone not found\n",
      "Skills: ['SQL', 'Machine Learning', 'Data Analysis', 'Python', 'AWS']\n",
      "Education: ['UNIVERSITY OF TECHNOLOGY SYDNEY', 'KENT INSTITUTE UNIVERSITY', 'Bachelor of Accounting\\n• Focus', 'CURTIN UNIVERSITY']\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/hainguyen/Downloads/Henry CV.pdf'\n",
    "\n",
    "result = parse_resume(model, path, sample_skills)\n",
    "\n",
    "# Print results\n",
    "print(\"Extracted Resume Information:\")\n",
    "for key, value in result.items():\n",
    "    print(f\"{key.capitalize()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>pay_period</th>\n",
       "      <th>location</th>\n",
       "      <th>company_id</th>\n",
       "      <th>views</th>\n",
       "      <th>med_salary</th>\n",
       "      <th>...</th>\n",
       "      <th>skills_desc</th>\n",
       "      <th>listed_time</th>\n",
       "      <th>posting_domain</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>work_type</th>\n",
       "      <th>currency</th>\n",
       "      <th>compensation_type</th>\n",
       "      <th>normalized_salary</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Requirements: \\n\\nWe are seeking a College or ...</td>\n",
       "      <td>1.713398e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>38480.0</td>\n",
       "      <td>8540.0</td>\n",
       "      <td>34021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1829192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Fort Collins, CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.712858e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>80521.0</td>\n",
       "      <td>8069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998357</td>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>We are currently accepting resumes for FOH - A...</td>\n",
       "      <td>1.713278e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>45202.0</td>\n",
       "      <td>39061.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     job_id            company_name                              title  \\\n",
       "0    921716   Corcoran Sawyer Smith              Marketing Coordinator   \n",
       "1   1829192                     NaN  Mental Health Therapist/Counselor   \n",
       "2  10998357  The National Exemplar         Assitant Restaurant Manager   \n",
       "\n",
       "                                         description  max_salary pay_period  \\\n",
       "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
       "1  At Aspen Therapy and Wellness , we are committ...        50.0     HOURLY   \n",
       "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
       "\n",
       "           location  company_id  views  med_salary  ...  \\\n",
       "0     Princeton, NJ   2774458.0   20.0         NaN  ...   \n",
       "1  Fort Collins, CO         NaN    1.0         NaN  ...   \n",
       "2    Cincinnati, OH  64896719.0    8.0         NaN  ...   \n",
       "\n",
       "                                         skills_desc   listed_time  \\\n",
       "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
       "1                                                NaN  1.712858e+12   \n",
       "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
       "\n",
       "   posting_domain  sponsored  work_type currency compensation_type  \\\n",
       "0             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "1             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "2             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "\n",
       "  normalized_salary  zip_code     fips  \n",
       "0           38480.0    8540.0  34021.0  \n",
       "1           83200.0   80521.0   8069.0  \n",
       "2           55000.0   45202.0  39061.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/linkedin-jobs-2023-2024/postings.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_id', 'company_name', 'title', 'description', 'max_salary',\n",
       "       'pay_period', 'location', 'company_id', 'views', 'med_salary',\n",
       "       'min_salary', 'formatted_work_type', 'applies', 'original_listed_time',\n",
       "       'remote_allowed', 'job_posting_url', 'application_url',\n",
       "       'application_type', 'expiry', 'closed_time',\n",
       "       'formatted_experience_level', 'skills_desc', 'listed_time',\n",
       "       'posting_domain', 'sponsored', 'work_type', 'currency',\n",
       "       'compensation_type', 'normalized_salary', 'zip_code', 'fips'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = df['title'].unique()\n",
    "\n",
    "titles = ['Data Analyst', 'Data Scientist', 'Data Engineer', 'ML Engineer', 'Machine Learning Engineer', 'AI Engineer',\n",
    "          'AI Researcher']\n",
    "df_filter = df[df.title.isin(titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB 5\n",
      "Piper Companies is seeking a Data Engineer to cluster large datasets across various container and data platforms depending on external client needs. The Data Engineer will work hands-on with challenging data engineering, data management, and analytics projects.\n",
      "\n",
      "Responsibilities of the Data Engineer include:\n",
      "\n",
      " Achieve and maintain proficiency with cluster and framework sizing, installation, debugging, performance optimization, migration, security and automation Collaborate with data scientists, analysts, business users, and IT teams to design, implement, and deploy data services and analytics. Use Continuous Integration/Continuous Delivery (CI/CD) concepts to engineer a standardized data environment Recommend and advise on optimal data models for data ingestion, integration, and visualization Integrate data from a variety of data source types\n",
      "\n",
      "Qualifications for the Data Engineer include: \n",
      "\n",
      " 6 years of experience in data engineering Experience with Snowflake, Databricks, Spark SQL, PySpark, and Python 3+ years cloud experience: Azure, AWS, or GCP\n",
      "\n",
      "Compensation for the Data Engineer include:\n",
      "\n",
      " Salary: $135,000-145,000 Benefits: Full Health/Dental/Vision, 401K, Pension, Annual Bonus\n",
      "\n",
      "JOB 6\n",
      "Piper Companies is looking for a Data Engineer for an Investment Firm in Wayne, PA for a Hybrid, Full-Time opportunity.\n",
      "\n",
      "﻿Responsibilities of the Data Engineer:\n",
      "\n",
      " Conduct data profiling, source-target mappings, ETL development, SQL tunings and optimization, testing and implementation Provide business and technical analysis for initiatives focusing on Data Warehouse and Business Intelligence solutions Collaborate with Business Intelligence Developers through dashboard and application development process for requirements gathering, feedback on proposed designs and models, and acceptance testing\n",
      "\n",
      "Qualifications of the Data Engineer:\n",
      "\n",
      " 10 years’ experience, with both hands-on and lead experience in supporting data warehousing solutions Must possess the following technical skills: ETL Tools: Enterprise class ETL tool (Talend is plus) Databases & Utilities: Experience with enterprise relational databases (Snowflake experience preferred) Platforms: Microsoft / Unix Expertise and fluency in SQL language is required Knowledge of scripting languages and job schedulers is required (Powershell, etc.) Experience with various integration patterns (e.g. Flat Files, Web Services, etc.) is required Knowledge of fundamental data modeling concepts (e.g. ER Diagrams, normalization, etc.) is required Familiarity with Python, Snowflake, Talend, XML/XSLT, and Cloud Services (AWS or Azure) are preferred Excellent troubleshooting and problem-solving skills; able to root cause and debug complex code in and efficient manner/with appropriate urgency Bachelor's degree in computer science, information technology or another computer-based discipline\n",
      "\n",
      "Compensation for the Data Engineer:\n",
      "\n",
      " Salary of $120K - $150K Hybrid Scheduling Comprehensive Benefits Package: Medical, Dental, Vision, 401K, PTO\n",
      "\n",
      "Keywords:\n",
      "\n",
      "Data, Data analysis, Engineering, Data Engineering, Data Wrangling, Data Manipulation, Data Automation, SQL, MySQL, SQL Server, RDMS, Relational Databases, Relational Database Management Systems, DBA, Database Management, Schemas, Queries, Query, DA, Extract, Transform, Load, scripting, data reports, data visualization, benefits, medical, dental, vision, 401K, pto, vacation, hybrid\n",
      "\n",
      "JOB 7\n",
      "Sr. Data Engineer – 3-month Contract – Remote, United States – W2 ONLY, NO C2C\n",
      "\n",
      "We are seeking an experienced Data Engineer to join our world leading footwear client. The ideal candidate will have 6-7 years of relevant experience, with a focus on practical application in AWS tech stack. Experience with Databricks, Spark, and Python for coding is essential.\n",
      "\n",
      "W2 ONLY, NO C2C*\n",
      "\n",
      "\n",
      "Key Responsibilities:\n",
      "\n",
      "Establish database management systems and standards.Document and communicate database design.Evaluate and install database systems.Code complex programs and build reports.Assist in UI and prototype design.Participate in quality assurance.Provide expertise in database design and optimization.\n",
      "\n",
      "\n",
      "Qualifications:\n",
      "\n",
      "Bachelor’s degree in Computer Science or related field.6-7 years of data engineering experience.Proficiency in AWS, Databricks, Spark, and Python.Ability to work in complex environments with diverse projects.Strong communication and collaboration skills.\n",
      "\n",
      "\n",
      "Mainz Brady Group is a technology staffing firm with offices in California, Oregon and Washington. We specialize in Information Technology and Engineering placements on a Contract, Contract-to-hire and Direct Hire basis. Mainz Brady Group is the recipient of multiple annual Excellence Awards from the Techserve Alliance, the leading association for IT and engineering staffing firms in the U.S.\n",
      "\n",
      "Mainz Brady Group is an Equal Opportunity Employer. We are committed to Diversity & Inclusion and incorporate non-discrimination best practices in all of our staffing processes. Mainz Brady Group does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, gender expression, age, disability or any other protected class.\n",
      "\n",
      "JOB 8\n",
      "Data Engineer\n",
      "We are seeking a motivated and detail-oriented Data Engineer to join our team based in Roanoke, Virginia. As a Data Engineer, you will play a crucial role in designing, developing and maintaining scalable data pipelines and transformations for business-critical use cases. In addition, you may take on various Software Development and Data Science responsibilities as we frequently share responsibilities and knowledge across our growing team.\n",
      "Responsibilities:Design, develop and maintain scalable data pipelines for extracting, transforming, and loading data from various sourcesCollaborate with cross-functional teams to identify data needs and determine the best data solutionsDevelop and implement data models to support business requirements and ensure data qualityEnsure the security and privacy of sensitive data by implementing appropriate access controlsMonitor and optimize data pipeline performance to ensure timely and accurate data deliveryDocument data pipeline processes, data dictionaries, and data storage solutions\n",
      "Requirements:Bachelor's degree in Computer Science, Computer Engineering, or a related technical fieldMinimum of five years of professional experience working as a Data Engineer or Software DeveloperStrong hands-on experience with data warehouse and transformation solutions, i.e. Domo, Snowflake or similarProficient in at least one scripting language such as Python, JavaScript, or RUnderstanding of data modeling, data integration and data quality processesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformStrong analytical and problem solving skillsFull Stack Software Development experience in a professional setting is highly desired, but not required\n",
      "This is an excellent opportunity for a driven and collaborative individual to make a significant impact in a dynamic and growing team. If you have a passion for data and a desire to work in a fast-paced and dynamic environment, we want to hear from you!\n",
      "\n",
      "JOB 9\n",
      "Overview:As a Data Engineer specializing in Cloud Image and Edge Device handling, you will play a crucial role inthe development and maintenance of our data infrastructure, particularly focused on managing imagedata from edge devices and processing it efficiently in cloud environments. You will be responsible fordesigning, implementing, and optimizing data pipelines to ensure seamless ingestion, storage, andanalysis of image data from various sources. Additionally, you will collaborate closely with crossfunctionalteams to integrate data-driven solutions into our products and services.Responsibilities:Data Pipeline Development: Design, implement, and maintain scalable data pipelines for ingesting,processing, and analyzing image data from edge devices to cloud-based storage and computingplatforms.Data Architecture: Design and Architect a Data Lake for structured and unstructured data over cloud(e.g., AWS, Azure, Google Cloud) for efficient storage, processing, and retrieval of data, ensuring highavailability, reliability, and performance.Edge Device Integration: Develop strategies and mechanisms for seamless integration of edge deviceswith cloud-based systems, including data synchronization, device management, and security protocols.Image Data Processing: Implement algorithms and techniques for real-time processing, transformation,and analysis of image data, optimizing for speed, accuracy, and resource efficiency.Data Quality and Governance: Implement data quality checks, validation processes, and governanceframeworks to ensure the integrity, consistency, and security of image data throughout its lifecycle.Performance Optimization: Identify performance bottlenecks in data pipelines and cloud infrastructure,and implement optimizations to improve throughput, latency, and cost-effectiveness.Collaboration and Communication: Collaborate with cross-functional teams, including softwareengineers, data scientists, and domain experts, to understand requirements, prioritize tasks, and deliverintegrated solutions.Documentation and Best Practices: Document design decisions, implementation details, and bestpractices for data engineering processes, ensuring knowledge sharing and continuous improvementwithin the team.Qualifications:Bachelor's or Master's degree in Computer Science, Engineering, or related field.Proven experience as a Data Engineer, preferably with specialization in handling image data.Strong proficiency in cloud computing platforms (e.g., AWS, Azure, Google Cloud) and related services(e.g., S3, EC2, Lambda, Kubernetes).Experience with data engineering tools like DataBrick, Snowflake, Glue etc.Proficiency in programming languages commonly used in data engineering (e.g., Python, Scala, Java) andfamiliarity with relevant libraries and frameworks (e.g., Apache Spark, TensorFlow, OpenCV).Solid understanding of data modeling, schema design, and database technologies (e.g., SQL, NoSQL,data warehouses).Familiarity with DevOps practices, CI/CD pipelines, and containerization technologies (e.g., Docker,Kubernetes).Strong problem-solving skills, analytical thinking, and attention to detail.Excellent communication and collaboration skills, with the ability to work effectively in a cross-functionalteam environment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 10):\n",
    "    print('JOB', i)\n",
    "    print(df_filter.iloc[i]['description'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('datasets/Technology Skills.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Example</th>\n",
       "      <th>Commodity Code</th>\n",
       "      <th>Commodity Title</th>\n",
       "      <th>Hot Technology</th>\n",
       "      <th>In Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>Adobe Acrobat</td>\n",
       "      <td>43232202</td>\n",
       "      <td>Document management software</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>AdSense Tracker</td>\n",
       "      <td>43232306</td>\n",
       "      <td>Data base user interface and query software</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>Atlassian JIRA</td>\n",
       "      <td>43232201</td>\n",
       "      <td>Content workflow software</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  O*NET-SOC Code             Title          Example  Commodity Code  \\\n",
       "0     11-1011.00  Chief Executives    Adobe Acrobat        43232202   \n",
       "1     11-1011.00  Chief Executives  AdSense Tracker        43232306   \n",
       "2     11-1011.00  Chief Executives   Atlassian JIRA        43232201   \n",
       "\n",
       "                               Commodity Title Hot Technology In Demand  \n",
       "0                 Document management software              Y         N  \n",
       "1  Data base user interface and query software              N         N  \n",
       "2                    Content workflow software              Y         N  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df['Commodity Title'].str.contains('pytorch')]['Commodity Title'].unique()\n",
    "len(df['Commodity Title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Microsoft Excel', 'Apple Numbers for Mac', 'Apple iWork Numbers',\n",
       "       \"Moody's KMV FAMAS\", 'Corel QuattroPro', 'IBM Lotus 1-2-3',\n",
       "       'Spreadsheet software', 'Google Sheets', 'Apple AppleWorks',\n",
       "       'Thomson GoSystem MyTaxInfo', 'EZAnalyze',\n",
       "       'Restaurant Operations & Management Spreadsheet Library',\n",
       "       'Spreadsheet applications', 'Spreadsheet programs',\n",
       "       'Rockport Integrated Excel Underwriting', 'PipingOffice'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Commodity Title'] == 'Spreadsheet software']['Example'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ORG\n",
      "SQL ORG\n",
      "Power BI ORG\n",
      "XYZ Corp ORG\n"
     ]
    }
   ],
   "source": [
    "# from pyresparser import ResumeParser\n",
    "\n",
    "# path = '/Users/hainguyen/Desktop/Harry_Nguyen_Resume.pdf'\n",
    "\n",
    "# data = ResumeParser(path).get_extracted_data()\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Worked as a Data Analyst using SQL and Power BI at XYZ Corp\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
